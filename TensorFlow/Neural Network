#Neural Network

#Define imports (tensor)
import tensorflow as tf
from tensorflow import keras

#Define imports (non-tensor)
import numpy as np
import matplotlib.pyplot as plt

#Using MNIST Fashion Dataset included in keras
#60,000 images for training, 10,000 for testing
fashion_mnist = keras.datasets.fashion_mnist #Load dataset
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() #Training/testing split

#Look at data, see what it looks like
train_images.shape #Should give (60000, 28, 28) -> 60000 images of 28*28 pixels

#Find one pixel
train_images[0, 23, 23] #Yeilds a number of 0 - 255 representing grayscale value of pixel (255 = white, 0 = black)

#Class names provided from TensorFlow website
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
'''
#Plot an image
plt.figure(1)
plt.imshow(train_images[3])
plt.colorbar()
plt.show()
'''

'''
Before creating the model, the data must go throughout preprocessing.
All greyscale values (0-255) must be translated to be between 0 and 1.
This can be done by dividing all values by 255.
This is done because the smaller values make it easier for the model to process
the values.
More info can be found here https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing
'''

#Divide by 255.0
train_images = train_images / 255.0
test_images = test_images / 255.0

#Model
model = keras.Sequential([ #Passing through layers sequentially
    keras.layers.Flatten(input_shape=(28, 28)), #Input later (1) -> flattens into 28*28 pixels
    keras.layers.Dense(128, activation='relu'), #Hidden layer (2) -> relu is rectified linear unit -> 128 is a number which is more or less a guess
    keras.layers.Dense(10, activation='softmax') #Output layer (3) -> 10 output neurons as 10 classes to predict for
]) #Softmax forms a probability distribution, so all numbers summed = 1

#Compiling the model
model.compile(optimizer='adam', #Algorithm that performs gradient descent
              loss = 'sparse_categorical_crossentropy', #More info here https://cwiki.apache.org/confluence/display/MXNET/Multi-hot+Sparse+Categorical+Cross-entropy#:~:text=Categorical%20Cross%20Entropy-,Definition,only%20belong%20to%20one%20class.
              metrics=['accuracy']) #Output we are looking for

#Training the model
model.fit(train_images, train_labels, epochs=1)

#Finding test accuracy
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)

print('Test accuracy:', test_acc) #If test_acc turns out lower than model.fit accuracy, epochs can be tweaked as overfitting has occurred

#For this situation, it turned out less epochs was actually better


#Making predictions
predictions = model.predict(test_images) #Yields a probability distribution of what is most likely
#print(class_names[np.argmax(predictions[0])])

#Make a function with argument of index to take an image at index i, predict it and show graph of it
def predict_this(i):
    print('This is a ', class_names[np.argmax(predictions[i])])
    plt.figure()
    plt.imshow(test_images[i])
    plt.colorbar()
    plt.show()

predict_this(16)






