# Tensor flow programme for classification

from __future__ import absolute_import, division, print_function, unicode_literals

# Define imports
import pandas as pd
import tensorflow as tf  # Tensorflow 2.0.0, other versions refused to work on my pc

# Column names and species
CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']
SPECIES = ['Setosa', 'Versicolor', 'Virginica']

# Obtaining files (Tensorflow website files)
train_path = tf.keras.utils.get_file("iris_training.csv",
                                     'https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')
test_path = tf.keras.utils.get_file("iris_test.csv",
                                    'https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv')

# Reading files - using keras (a module of tensorFlow) to obtain datasets and make them a pandas dataframe
train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)
test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)

# remove species column to use as label
train_y = train.pop('Species')
test_y = test.pop('Species')


# print(train.head()) #Species column gone

# print(train.shape) #120 entries with 4 features

# Defining input function
def input_fn(features, labels, training=True, batch_size=256):
    # Convert labels to Dataset
    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))

    # Shuffle and repeat if training=True
    if training:
        dataset = dataset.shuffle(1000).repeat()

    # Return
    return dataset.batch(batch_size)


# Define feature columns
my_feature_columns = []
for key in train.keys():
    my_feature_columns.append(tf.feature_column.numeric_column(key=key))
# print(my_feature_columns)

# Building a classification model - using a DNNClassifier, which TensorFlow reccomends for classification
# Building a DNN with 2 hidden layers with 30 and 10 hidden nodes each
classifier = tf.estimator.DNNClassifier(
    feature_columns=my_feature_columns,
    # 2 hidden layers of 30 and 10 nodes
    hidden_units=[30, 10],
    # model must choose between 3 classes.
    n_classes=3)

# Training the model
classifier.train(  # A lambda is a one line anonymous function - does whatever is after it
    input_fn=lambda: input_fn(train, train_y, training=True),
    steps=5000)  # Similar to an epoch, but making it look at 5000 data points

# Evaluating the model
eval_result = classifier.evaluate(
    input_fn=lambda: input_fn(test, test_y, training=False))  # No steps: looking at data set once
print('\nTest set accuracy: {accuracy:0.3f}\n'.format(**eval_result))  # Print accuracy


#######################################################################################################
# PREDICTION FUNCTION to allow user to predict a single flower based on input data
# Predictions
def input_fn_prediction(features, batch_size=256):
    # Convert the inputs to dataset w/out labels
    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)


features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']
predict = {}  # Predict dictionary

print("Please type numeric values as prompted.")
for feature in features:
    valid = True
    while valid:
        val = input(feature + ": ")  # Input feature:
        if not val.isdigit(): valid = False  # Digit must be entered

    predict[feature] = [float(val)]

predictions = classifier.predict(input_fn=lambda: input_fn_prediction(predict))
for pred_dict in predictions:
    class_id = pred_dict['class_ids'][0]
    probability = pred_dict['probabilities'][class_id]

    print('Prediction is "{}" ({:.1f}%)'.format(SPECIES[class_id], 100 * probability))

# Example input with expected classes
expected = ['Setosa', 'Versicolor', 'Virginica']
predict_x = {
    'SepalLength': [5.1, 5.9, 6.9],
    'SepalWidth': [3.3, 3.0, 3.1],
    'PetalLength': [1.7, 4.2, 5.4],
    'PetalWidth': [0.5, 1.5, 2.1],
}
